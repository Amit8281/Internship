{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a7fde2",
   "metadata": {},
   "source": [
    "## Web Scraping Assignment-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a9a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in d:\\jupyter\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in d:\\jupyter\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\jupyter\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\jupyter\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\jupyter\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in d:\\jupyter\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in d:\\jupyter\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\jupyter\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in d:\\jupyter\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\jupyter\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4a2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException ,NoSuchElementException\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e88d7a",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "- 1. First get the webpage https://www.naukri.com/\n",
    "- 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "- 3. Then click the searchbutton.\n",
    "- 4. Then scrape the data for the first 10 jobs results you get.\n",
    "- 5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd1d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08388bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri.com page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f226121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8618aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the  location as required in the question\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f287bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308cf50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Portcast</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job-title  \\\n",
       "1   Data Analyst - IIT/BITS/Startups   \n",
       "2             Data Analyst - FinTech   \n",
       "3             Data Analyst - FinTech   \n",
       "4             Data Analyst - FinTech   \n",
       "5   Data Analyst - IIT/BITS/Startups   \n",
       "6               Banking Data Analyst   \n",
       "7                       Data Analyst   \n",
       "8                       Data Analyst   \n",
       "9                       Data Analyst   \n",
       "10                      Data Analyst   \n",
       "\n",
       "                                         job-location      company_name  \\\n",
       "1                                 Bangalore/Bengaluru      AVE Promagne   \n",
       "2   Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...      Primo Hiring   \n",
       "3   Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Primo Hiring   \n",
       "4   Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Primo Hiring   \n",
       "5                                 Bangalore/Bengaluru      AVE Promagne   \n",
       "6   Bangalore/Bengaluru, Hyderabad/Secunderabad, G...           Coforge   \n",
       "7                                 Bangalore/Bengaluru           Dpdzero   \n",
       "8                                 Bangalore/Bengaluru  Juniper Networks   \n",
       "9   Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...          Infogain   \n",
       "10  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...          Portcast   \n",
       "\n",
       "   experience_required  \n",
       "1              1-5 Yrs  \n",
       "2              1-2 Yrs  \n",
       "3              1-2 Yrs  \n",
       "4              1-2 Yrs  \n",
       "5              1-5 Yrs  \n",
       "6             5-10 Yrs  \n",
       "7              1-3 Yrs  \n",
       "8              5-9 Yrs  \n",
       "9              4-7 Yrs  \n",
       "10             2-6 Yrs  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty lists to store the scraped data\n",
    "job_titles = []\n",
    "company_name = []\n",
    "job_location = []\n",
    "experience_required = []\n",
    "\n",
    "# scrape job titles of first 10 jobs\n",
    "job_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in job_tags[:10]:\n",
    "    job= i.text\n",
    "    job_titles.append(job)\n",
    "\n",
    "# scrape company names of first 10 jobs\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[:10]:\n",
    "    company= i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scrape job locations of first 10 jobs\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# scrape experience required for first 10 jobs\n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[:10]:\n",
    "    experience= i.text\n",
    "    experience_required.append(experience)\n",
    "\n",
    "# create pandas dataframe from the scraped data\n",
    "df = pd.DataFrame({'job-title':job_titles,\n",
    "                   'job-location':job_location, \n",
    "                   'company_name':company_name, \n",
    "                   'experience_required':experience_required})\n",
    "\n",
    "\n",
    "\n",
    " # Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "# print the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5196a",
   "metadata": {},
   "source": [
    "## Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "- 1. First get the webpage https://www.naukri.com/\n",
    "- 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "- location” field.\n",
    "- 3. Then click the searchbutton.\n",
    "- 4. Then scrape the data for the first 10 jobs results youget.\n",
    "- 5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "046e6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c14a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri.com page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34159739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b596aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the  location as required in the question\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a599574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f3dc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job-location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst - Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Analyst Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analytics Specialist - Artificial Intelligence...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist, Engineering at Google</td>\n",
       "      <td>Blob Infotech</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Opportunity | Data Scientist | Tavant India</td>\n",
       "      <td>Tavant Technologies</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sr. Data Scientist - Python / ML / DL</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai, Chandigarh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job-title         company_name  \\\n",
       "1                             Data Science Specialist            Accenture   \n",
       "2                                  Data Scientist_NLP    Fractal Analytics   \n",
       "3                     Machine Learning (AI) Architect           Persistent   \n",
       "4                 Data Science Analyst - Data Science            Accenture   \n",
       "5                   Data Science Analyst Data Science            Accenture   \n",
       "6   Analytics Specialist - Artificial Intelligence...            Accenture   \n",
       "7                               Senior Data Scientist              Walmart   \n",
       "8               Data Scientist, Engineering at Google        Blob Infotech   \n",
       "9         Opportunity | Data Scientist | Tavant India  Tavant Technologies   \n",
       "10              Sr. Data Scientist - Python / ML / DL         AVE Promagne   \n",
       "\n",
       "                                         job-location  \n",
       "1   Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  \n",
       "2   Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...  \n",
       "3   Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8   Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...  \n",
       "9   Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...  \n",
       "10  Bangalore/Bengaluru, Noida, Mumbai, Chandigarh...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty lists to store the scraped data\n",
    "Data_job = []\n",
    "Data_company = []\n",
    "Data_location = []\n",
    "\n",
    "\n",
    "# scrape job titles of first 10 jobs\n",
    "job_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in job_tags[:10]:\n",
    "    job= i.text\n",
    "    Data_job.append(job)\n",
    "\n",
    "# scrape company names of first 10 jobs\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[:10]:\n",
    "    company= i.text\n",
    "    Data_company.append(company)\n",
    "\n",
    "# scrape job locations of first 10 jobs\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[:10]:\n",
    "    location = i.text\n",
    "    Data_location.append(location)\n",
    "\n",
    "\n",
    "\n",
    "# create pandas dataframe from the scraped data\n",
    "df = pd.DataFrame({'job-title':Data_job, \n",
    "                   'company_name':Data_company,\n",
    "                   'job-location':Data_location})\n",
    "\n",
    "\n",
    "\n",
    " # Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "# print the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a2ca1",
   "metadata": {},
   "source": [
    "## Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e06e0",
   "metadata": {},
   "source": [
    "### You have to use the location and salary filter.\n",
    "### You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "### You have to scrape the job-title, job-location, company name, experience required.\n",
    "### The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "### The task will be done as shown in the below steps:\n",
    "- 1. first get thewebpage https://www.naukri.com/\n",
    "- 2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "- 3. Then click the searchbutton.\n",
    "- 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "- 5. Then scrape the data for the first 10 jobs results youget.\n",
    "- 6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f213104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace0cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri.com page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "147d0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0102525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the salary\n",
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf0651ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the location \n",
    "locationss = driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]')\n",
    "locationss.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b18ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the salary\n",
    "salary = driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f67c4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - II (Contract)</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>Noida</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Scientist - Bioinformatics</td>\n",
       "      <td>Biopeople India</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Profit By Outsourcing</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Assistant Manager - Data Scientist</td>\n",
       "      <td>Fidelity International</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Job-title             Company_name  \\\n",
       "1                 Junior Data Scientist                 Analytos   \n",
       "2                        Data Scientist                Blackbuck   \n",
       "3                        Data Scientist                 Analytos   \n",
       "4                 Junior Data Scientist                   Adidas   \n",
       "5        Data Scientist - II (Contract)                   Netomi   \n",
       "6                        Data Scientist  Gujarat Fluorochemicals   \n",
       "7   Research Scientist - Bioinformatics          Biopeople India   \n",
       "8                    Data Scientist - I                   Netomi   \n",
       "9             Machine Learning Engineer    Profit By Outsourcing   \n",
       "10   Assistant Manager - Data Scientist   Fidelity International   \n",
       "\n",
       "                                         Job-location Experience_required  \n",
       "1   Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...             0-2 Yrs  \n",
       "2               Gurgaon/Gurugram, Bangalore/Bengaluru             3-7 Yrs  \n",
       "3   Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...             2-4 Yrs  \n",
       "4     Gurgaon/Gurugram, United States (USA), Bulgaria             1-6 Yrs  \n",
       "5                                    Gurgaon/Gurugram             3-7 Yrs  \n",
       "6                                               Noida             1-2 Yrs  \n",
       "7                                    Gurgaon/Gurugram             0-2 Yrs  \n",
       "8                                    Gurgaon/Gurugram             3-6 Yrs  \n",
       "9                                               Noida             2-7 Yrs  \n",
       "10                                   Gurgaon/Gurugram             5-7 Yrs  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty lists to store the scraped data\n",
    "DataScience_job = []\n",
    "DataScience_company_name = []\n",
    "DataScience_job_location = []\n",
    "DataScience_experience_required = []\n",
    "\n",
    "# scrape job titles of first 10 jobs\n",
    "job_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in job_tags[:10]:\n",
    "    job= i.text\n",
    "    DataScience_job.append(job)\n",
    "\n",
    "# scrape company names of first 10 jobs\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[:10]:\n",
    "    company= i.text\n",
    "    DataScience_company_name.append(company)\n",
    "\n",
    "# scrape job locations of first 10 jobs\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[:10]:\n",
    "    location = i.text\n",
    "    DataScience_job_location.append(location)\n",
    "\n",
    "# scrape experience required for first 10 jobs\n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[:10]:\n",
    "    experience= i.text\n",
    "    DataScience_experience_required.append(experience)\n",
    "\n",
    "# create pandas dataframe from the scraped data\n",
    "df = pd.DataFrame({'Job-title':DataScience_job,\n",
    "                   'Company_name':DataScience_company_name, \n",
    "                   'Job-location':DataScience_job_location,\n",
    "                   'Experience_required':DataScience_experience_required})\n",
    "\n",
    "\n",
    "\n",
    " # Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "# print the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80f69d",
   "metadata": {},
   "source": [
    "## Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "- 1. Brand\n",
    "- 2. ProductDescription\n",
    "- 3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad83abb",
   "metadata": {},
   "source": [
    "### To scrape the data you have to go through following steps:\n",
    "- 1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "- 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "- 3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap therequired data asusual.\n",
    "- 4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "- 5. Now scrape data from this page asusual\n",
    "- 6. Repeat this until you get data for 100sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db5cc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea6a75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the https://www.flipkart.com/ page on automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf9bebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "Glasses = driver.find_element(By.CLASS_NAME,\"_3704LK \")\n",
    "Glasses.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02abb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "search = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aab1545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "      <td>₹965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>₹224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ARICKS</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Shaah Collection</td>\n",
       "      <td>UV Protection Aviator, Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                 ProductDescription Price\n",
       "1       VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹849\n",
       "2       VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)  ₹965\n",
       "3           Elligator             UV Protection Wayfarer Sunglasses (53)  ₹149\n",
       "4           Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  ₹149\n",
       "5              PIRASO           UV Protection Clubmaster Sunglasses (54)  ₹224\n",
       "..                ...                                                ...   ...\n",
       "96             ARICKS  by Lenskart Polarized, UV Protection Cat-eye S...  ₹233\n",
       "97           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹539\n",
       "98          Elligator             UV Protection Wayfarer Sunglasses (56)  ₹249\n",
       "99   Shaah Collection    UV Protection Aviator, Wayfarer Sunglasses (55)  ₹185\n",
       "100     VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...  ₹873\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty lists to store the required data\n",
    "Brand=[]\n",
    "productdescription=[]\n",
    "price=[]\n",
    "\n",
    "# Define the start and end page numbers\n",
    "start = 0\n",
    "end = 3\n",
    "\n",
    "# Loop through the pages\n",
    "for page in range(start, end):\n",
    "    # Find all the elements for Brand tag and append their text to the Brand list\n",
    "    Brand_tag = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in Brand_tag:\n",
    "        Brand.append(i.text)\n",
    "    \n",
    "    # Find all the elements for Product tag and append their text to the productdescription list\n",
    "    product_tag = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tag:\n",
    "        productdescription.append(i.text)\n",
    "    \n",
    "    # Find all the elements for Price tag and append their text to the price list\n",
    "    price_tag = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    # Find the next button and click on it\n",
    "    nextbutton = driver.find_element(By.CLASS_NAME,'_1LKTO3')\n",
    "    nextbutton.click()\n",
    "    # Wait for 3 seconds for the next page to load\n",
    "    time.sleep(3)\n",
    "    \n",
    "# Get only the first 100 items from each of the lists\n",
    "brand = Brand[:100]\n",
    "product = productdescription[:100]\n",
    "price = price[:100]\n",
    "\n",
    "# Create a pandas dataframe using the data obtained and store it in a variable named df_sneak\n",
    "df = pd.DataFrame({\"Brand\":brand,\n",
    "                  \"ProductDescription\":product,\n",
    "                  \"Price\":price})\n",
    " # Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22fb70",
   "metadata": {},
   "source": [
    "## Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fdpid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c81c3",
   "metadata": {},
   "source": [
    "## As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "- 1. Rating\n",
    "- 2. Review summary\n",
    "- 3. Full review\n",
    "- 4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa02011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1620e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the \"https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fdpid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\" page on automated chrome browser\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1db04ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>Just got this iphone 11\\nAnd it is most powerf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating               Review  \\\n",
       "1        5       Simply awesome   \n",
       "2        5     Perfect product!   \n",
       "3        5  Best in the market!   \n",
       "4        4      Value-for-money   \n",
       "5        5   Highly recommended   \n",
       "..     ...                  ...   \n",
       "96       5     Perfect product!   \n",
       "97       5   Highly recommended   \n",
       "98       5   Highly recommended   \n",
       "99       5     Perfect product!   \n",
       "100      4      Value-for-money   \n",
       "\n",
       "                                           Full Review  \n",
       "1    Really satisfied with the Product I received.....  \n",
       "2    Amazing phone with great cameras and better ba...  \n",
       "3    Great iPhone very snappy experience as apple k...  \n",
       "4    I'm Really happy with the product\\nDelivery wa...  \n",
       "5    It's my first time to use iOS phone and I am l...  \n",
       "..                                                 ...  \n",
       "96   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "97   iphone 11 is a very good phone to buy only if ...  \n",
       "98   Amazing camera quality as expected, battery al...  \n",
       "99   It is just awesome mobile for this price from ...  \n",
       "100  Just got this iphone 11\\nAnd it is most powerf...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty lists to store the required data\n",
    "rating=[]\n",
    "review=[]\n",
    "full_review=[]\n",
    "\n",
    "# Define the start and end page numbers\n",
    "start = 0\n",
    "end = 10\n",
    "\n",
    "# Loop through the pages\n",
    "for page in range(start, end):\n",
    "    # Find all the elements for rating tag and append their text to the rating list\n",
    "    rating_tag = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tag:\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    # Find all the elements for review tag and append their text to the review list\n",
    "    review_tag = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tag:\n",
    "        review.append(i.text)\n",
    "    \n",
    "    # Find all the elements for full review tag and append their text to the full review list\n",
    "    full_review_tag = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_review_tag:\n",
    "        full_review.append(i.text)\n",
    "    \n",
    "    # Find the next button and click on it\n",
    "    nextbutton = driver.find_element(By.CLASS_NAME,'_1LKTO3')\n",
    "    nextbutton.click()\n",
    "    # Wait for 3 seconds for the next page to load\n",
    "    time.sleep(3)\n",
    "    \n",
    "# Get only the first 100 items from each of the lists\n",
    "rating = rating[:100]\n",
    "review = review[:100]\n",
    "full_review = full_review[:100]\n",
    "\n",
    "# Create a pandas dataframe using the data obtained and store it in a variable named df\n",
    "df = pd.DataFrame({\"Rating\":rating,\n",
    "                  \"Review\":review,\n",
    "                  \"Full Review\":full_review})\n",
    " # Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672302f",
   "metadata": {},
   "source": [
    "## Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 3 attributes of each sneaker:\n",
    "- 1. Brand\n",
    "- 2. ProductDescription\n",
    "- 3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84724a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3e8b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart.com page on automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d08f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "sneakers = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "sneakers.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b25b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "search = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "677e74f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asian</td>\n",
       "      <td>asian Pride White Sneakers,Casuals,Walking,Loa...</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RINDAS</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Trendy Casual Shoe For Men Pack Of 2 Sneakers ...</td>\n",
       "      <td>₹539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MOZAFIA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Thunder-01 White Canvas, Sneakers For Men</td>\n",
       "      <td>₹873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product Description Price\n",
       "1       asian  asian Pride White Sneakers,Casuals,Walking,Loa...  ₹849\n",
       "2    RapidBox                                   Sneakers For Men  ₹965\n",
       "3        aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...  ₹149\n",
       "4      RINDAS                                 Sneakers For Women  ₹149\n",
       "5       BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men  ₹224\n",
       "..        ...                                                ...   ...\n",
       "96     Labbin      Combo Pack Of 2 Casual Shoes Sneakers For Men  ₹233\n",
       "97     BRUTON  Trendy Casual Shoe For Men Pack Of 2 Sneakers ...  ₹539\n",
       "98    MOZAFIA                                   Sneakers For Men  ₹249\n",
       "99      BIRDE                                   Sneakers For Men  ₹185\n",
       "100    Layasa          Thunder-01 White Canvas, Sneakers For Men  ₹873\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty list to store the data\n",
    "brand =[]\n",
    "product_description=[]\n",
    "price\n",
    "\n",
    "# Set the start and end pages to scrape\n",
    "start = 0\n",
    "end = 3\n",
    "# Loop through the pages and scrape data\n",
    "for page in range(start, end):\n",
    "    \n",
    "    # Find all the brand elements on the current page and append them to the brand list\n",
    "    brand_tag = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tag:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "        \n",
    "    # Find all the product description elements on the current page and append them to the product description list\n",
    "    product_tag = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tag:\n",
    "        product_description.append(i.text)\n",
    "        \n",
    "    # Find all the price elements on the current page and append them to the price list\n",
    "    price_tag = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "        \n",
    "        \n",
    "     # Click on the next button to move to the next page\n",
    "    nexts = driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    nexts.click()\n",
    "    \n",
    "    # Use a time.sleep() to wait for the next page to load\n",
    "    time.sleep(3)\n",
    "    \n",
    "# Truncate the lists to 100 elements if necessary    \n",
    "Brand = brand[:100]\n",
    "Product_description =product_description[:100]\n",
    "Price = price[:100]\n",
    "\n",
    "\n",
    "# Create a pandas dataframe from the scraped data and display it\n",
    "df= pd.DataFrame({'Brand': Brand,\n",
    "                         'Product Description': Product_description,\n",
    "                         'Price': Price})\n",
    "df.index = range(1, len(df)+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055689f",
   "metadata": {},
   "source": [
    "## Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23cecb",
   "metadata": {},
   "source": [
    "### After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "- 1. Title\n",
    "- 2. Ratings\n",
    "- 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83da5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c10b5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the https://www.amazon.in/ page on automated chrome browser\n",
    "driver.get('https://www.amazon.in/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5daa1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering the designation as required in the question\n",
    "laptop = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "laptop.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41333cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc54d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the cpu\n",
    "cpu = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[6]/span[9]/li/span/a/span')\n",
    "cpu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab488ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>298</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td>72</td>\n",
       "      <td>94,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy Book2 (NP750) Intel 12th Gen co...</td>\n",
       "      <td>107</td>\n",
       "      <td>69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>131</td>\n",
       "      <td>88,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...</td>\n",
       "      <td>13</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Zenbook Pro 14 Duo OLED (2022) Dual Scree...</td>\n",
       "      <td>3</td>\n",
       "      <td>1,24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 Intel Core i7 6t...</td>\n",
       "      <td>69</td>\n",
       "      <td>25,067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td>22</td>\n",
       "      <td>1,29,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion 5 Pro Intel Core i7-12700H 16\" (...</td>\n",
       "      <td>2</td>\n",
       "      <td>2,18,108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>55</td>\n",
       "      <td>84,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Rating     Price\n",
       "1   HP Victus Gaming Latest 12th Gen Intel Core i7...    298    79,990\n",
       "2   ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...     72    94,989\n",
       "3   Samsung Galaxy Book2 (NP750) Intel 12th Gen co...    107    69,990\n",
       "4   HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    131    88,990\n",
       "5   ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...     13    79,990\n",
       "6   ASUS Zenbook Pro 14 Duo OLED (2022) Dual Scree...      3  1,24,990\n",
       "7   (Renewed) Dell Latitude E7470 Intel Core i7 6t...     69    25,067\n",
       "8   ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...     22  1,29,989\n",
       "9   Lenovo Legion 5 Pro Intel Core i7-12700H 16\" (...      2  2,18,108\n",
       "10  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...     55    84,999"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty lists to store the scraped data\n",
    "title = []\n",
    "rating = []\n",
    "price = []\n",
    "\n",
    "\n",
    "# scrape job titles of first 10 laptop\n",
    "title_tags = driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in title_tags[:10]:\n",
    "    T= i.text\n",
    "    title.append(T)\n",
    "\n",
    "# scrape rating of first 10 laptop\n",
    "rating_tags = driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]')\n",
    "for i in rating_tags[:10]:\n",
    "    R= i.text\n",
    "    rating.append(R)\n",
    "\n",
    "# scrape price of first 10 laptop\n",
    "price_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[:10]:\n",
    "    P = i.text\n",
    "    price.append(P)\n",
    "\n",
    "\n",
    "\n",
    "# create pandas dataframe from the scraped data\n",
    "df = pd.DataFrame({'Title':title, \n",
    "                   'Rating':rating,\n",
    "                   'Price':price})\n",
    "\n",
    "\n",
    "\n",
    " # Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "# print the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23f617",
   "metadata": {},
   "source": [
    "## Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "### The above task will be done in following steps:\n",
    "- 1. First get the webpagehttps://www.azquotes.com/\n",
    "- 2. Click on TopQuotes\n",
    "- 3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da684797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25530738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the https://www.azquotes.com/ page on automated chrome browser\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6490a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on top Quotes to search the required data \n",
    "quotes = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]')\n",
    "quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96effd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type Of Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quotes              Author  \\\n",
       "1     The essence of strategy is choosing what not t...      Michael Porter   \n",
       "2     One cannot and must not try to erase the past ...          Golda Meir   \n",
       "3     Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "4     Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "5     You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "...                                                 ...                 ...   \n",
       "996   Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "997   America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "998   For every disciplined effort there is a multip...            Jim Rohn   \n",
       "999   The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "1000  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                Type Of Quotes  \n",
       "1     Essence, Deep Thought, Transcendentalism  \n",
       "2                    Inspiration, Past, Trying  \n",
       "3                          Country, Peace, War  \n",
       "4           Inspirational, Motivational, Death  \n",
       "5                 4th Of July, Food, Patriotic  \n",
       "...                                        ...  \n",
       "996          Love, Inspirational, Motivational  \n",
       "997                     Gun, Two, Qualms About  \n",
       "998      Inspirational, Greatness, Best Effort  \n",
       "999                     Spiritual, Truth, Yoga  \n",
       "1000      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty list to store the data\n",
    "Quote =[]\n",
    "Author =[]\n",
    "Type_of_quotes=[]\n",
    "# Set the start and end pages to scrape\n",
    "start = 0\n",
    "end = 10\n",
    "# Loop through the pages and scrape data\n",
    "for page in range(start, end):\n",
    "    #scrap quote tag and appent it in Quote list\n",
    "    quote_tag = driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tag:\n",
    "        Quote.append(i.text)\n",
    "     #Scrap author tag and append in Author list   \n",
    "    author_tag = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tag:\n",
    "        Author.append(i.text)\n",
    "    #scrap type of Quote tag and append in type of quotess list\n",
    "    type_of_quotes_tag = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_of_quotes_tag:\n",
    "        Type_of_quotes.append(i.text)\n",
    "    \n",
    "    # Click on the next button to move to the next page\n",
    "    nexts = driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[4]/li[12]')\n",
    "    nexts.click()\n",
    "    \n",
    "    # Use a time.sleep() to wait for the next page to load\n",
    "    time.sleep(3)\n",
    "df = pd.DataFrame({'Quotes':Quote,'Author':Author,'Type Of Quotes':Type_of_quotes})\n",
    "#Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "#print Dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933fa921",
   "metadata": {},
   "source": [
    "## Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/. This task will be done in following steps:\n",
    "- 1. First get the webpagehttps://www.jagranjosh.com/\n",
    "- 2. Then You have to click on the GK option\n",
    "- 3. Then click on the List of all Prime Ministers of India\n",
    "- 4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2570532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e14035c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the https://www.jagranjosh.com/ page on automated chrome browser\n",
    "driver.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c679131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "gk = driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d05d416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button to search the required data \n",
    "pm = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "pm.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de36893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born Dead</th>\n",
       "      <th>Term Of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,\\n13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966\\n1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966\\n13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977\\n11 years, 59...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 \\n2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980\\n170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984\\n4 years, 2...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989\\n5 years, 3...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990\\n343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991\\n223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996\\n4 years, 330 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996\\n16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997\\n324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 \\n332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 \\n6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   \\n10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born Dead  \\\n",
       "1             Jawahar Lal Nehru   (1889–1964)   \n",
       "2     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "3           Lal Bahadur Shastri   (1904–1966)   \n",
       "4   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "5                 Indira Gandhi   (1917–1984)   \n",
       "6                 Morarji Desai   (1896–1995)   \n",
       "7                  Charan Singh   (1902–1987)   \n",
       "8                 Indira Gandhi   (1917–1984)   \n",
       "9                  Rajiv Gandhi   (1944–1991)   \n",
       "10                  V. P. Singh   (1931–2008)   \n",
       "11              Chandra Shekhar   (1927–2007)   \n",
       "12          P. V. Narasimha Rao   (1921–2004)   \n",
       "13         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "14             H. D. Deve Gowda   (born 1933)   \n",
       "15           Inder Kumar Gujral   (1919–2012)   \n",
       "16         Atal Bihari Vajpayee   (1924-2018)   \n",
       "17               Manmohan Singh   (born 1932)   \n",
       "18                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term Of Office  \\\n",
       "1   15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "2                27 May 1964 to 9 June 1964,\\n13 days   \n",
       "3    9 June 1964 to 11 January 1966\\n1 year, 216 days   \n",
       "4         11 January 1966 to 24 January 1966\\n13 days   \n",
       "5   24 January 1966 to 24 March 1977\\n11 years, 59...   \n",
       "6   24 March 1977 to  28 July 1979 \\n2 year, 126 days   \n",
       "7           28 July 1979 to 14 January 1980\\n170 days   \n",
       "8   14 January 1980 to 31 October 1984\\n4 years, 2...   \n",
       "9   31 October 1984 to 2 December 1989\\n5 years, 3...   \n",
       "10      2 December 1989 to 10 November 1990\\n343 days   \n",
       "11         10 November 1990 to 21 June 1991\\n223 days   \n",
       "12     21 June 1991 to 16 May 1996\\n4 years, 330 days   \n",
       "13                16 May 1996 to 1 June 1996\\n16 days   \n",
       "14             1 June 1996 to 21 April 1997\\n324 days   \n",
       "15          21 April 1997 to 19 March 1998 \\n332 days   \n",
       "16    19 March 1998 to 22 May 2004 \\n6 years, 64 days   \n",
       "17    22 May 2004 to 26 May 2014   \\n10 years, 4 days   \n",
       "18                              26 May 2014 - Present   \n",
       "\n",
       "                                              Remarks  \n",
       "1   The first prime minister of India and the long...  \n",
       "2                            First acting PM of India  \n",
       "3   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "4                                                   -  \n",
       "5                First female Prime Minister of India  \n",
       "6   Oldest to become PM (81 years old) and first t...  \n",
       "7             Only PM who did not face the Parliament  \n",
       "8   The first lady who served as PM for the second...  \n",
       "9                Youngest to become PM (40 years old)  \n",
       "10  First PM to step down after a vote of no confi...  \n",
       "11              He belongs to  Samajwadi Janata Party  \n",
       "12                          First PM from south India  \n",
       "13                             PM for shortest tenure  \n",
       "14                          He belongs to  Janata Dal  \n",
       "15                                             ------  \n",
       "16   The first non-congress PM who completed a ful...  \n",
       "17                                      First Sikh PM  \n",
       "18  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty lists to store the data\n",
    "Name=[]\n",
    "Born_Dead=[]\n",
    "Term_of_office=[]\n",
    "Remarks=[]\n",
    "\n",
    "# Find all td elements on the page and append their text to the Name list\n",
    "name_tag = driver.find_elements(By.TAG_NAME,'td')\n",
    "for i in name_tag:\n",
    "    Name.append(i.text)\n",
    "\n",
    "# Find all td elements on the page and append their text to the Born_Dead list\n",
    "brand_tag = driver.find_elements(By.TAG_NAME,'td')\n",
    "for i in brand_tag:\n",
    "    Born_Dead.append(i.text)\n",
    "\n",
    "# Find all td elements on the page and append their text to the Term_of_office list\n",
    "term_tag = driver.find_elements(By.TAG_NAME,'td')\n",
    "for i in term_tag:\n",
    "    Term_of_office.append(i.text)\n",
    "\n",
    "# Find all td elements on the page and append their text to the Remarks list\n",
    "Remarks_tag = driver.find_elements(By.TAG_NAME,'td')\n",
    "for i in Remarks_tag:\n",
    "    Remarks.append(i.text)\n",
    "\n",
    "# Slice the Name list to extract every 5th element starting from the second element\n",
    "# This extracts the values for the \"Name\" column of the table\n",
    "Name = Name[1:90:5]\n",
    "\n",
    "# Slice the Born_Dead list to extract every 5th element starting from the third element\n",
    "# This extracts the values for the \"Born Dead\" column of the table\n",
    "Born_Dead = Born_Dead[2:90:5]\n",
    "\n",
    "# Slice the Term_of_office list to extract every 5th element starting from the fourth element\n",
    "# This extracts the values for the \"Term Of Office\" column of the table\n",
    "Term_of_office = Term_of_office[3:90:5]\n",
    "\n",
    "# Slice the Remarks list to extract every 5th element starting from the fifth element\n",
    "# This extracts the values for the \"Remarks\" column of the table\n",
    "Remarks = Remarks[4:90:5]\n",
    "\n",
    "# Create a pandas DataFrame using a dictionary of the lists\n",
    "df = pd.DataFrame({'Name':Name,'Born Dead':Born_Dead,'Term Of Office':Term_of_office,'Remarks':Remarks})\n",
    "#Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "# Print the DataFrame to the console\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a5cec8",
   "metadata": {},
   "source": [
    "## Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/ This task will be done in following steps:\n",
    "- 1. First get the webpagehttps://www.motor1.com/\n",
    "- 2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "- 3. Then click on 50 most expensive carsin the world..\n",
    "- 4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e10d72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"D:\\CHROME DOWNLODE\\chromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7cc6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the https://www.motor1.com/ on automated chrome browser\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b5768e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the text in the search box\n",
    "data = driver.find_element(By.XPATH,'/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "data.send_keys('50 Most expensive cars in the world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec37e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the search button\n",
    "searchs= driver.find_element(By.XPATH,'/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "searchs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9f58bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the 50 most expensive cars section\n",
    "cars = driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "cars.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4d7df1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Most Expensive Cars In The World</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Car Name                        Price\n",
       "1                      De Tomaso P72          Price: $1.3 Million\n",
       "2                  Ferrari LaFerrari          Price: $1.4 Million\n",
       "3                      Pagani Huayra          Price: $1.4 Million\n",
       "4                        Czinger 21C          Price: $1.7 Million\n",
       "5                      Ferrari Monza          Price: $1.7 Million\n",
       "6                 Gordon Murray T.33          Price: $1.7 Million\n",
       "7                  Koenigsegg Gemera          Price: $1.7 Million\n",
       "8                        Zenvo TSR-S          Price: $1.7 Million\n",
       "9                 Hennessey Venom F5          Price: $1.7 Million\n",
       "10                   Bentley Bacalar          Price: $1.8 Million\n",
       "11     Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
       "12            Bentley Mulliner Batur          Price: $1.9 Million\n",
       "13                      Deus Vayanne          Price: $2.0 Million\n",
       "14                       SSC Tuatara          Price: $2.0 Million\n",
       "15                       Lotus Evija         Price: $2.0 Million*\n",
       "16               Aston Martin Vulcan          Price: $2.1 Million\n",
       "17                        Delage D12          Price: $2.3 Million\n",
       "18                 McLaren Speedtail          Price: $2.3 Million\n",
       "19                      Rimac Nevera          Price: $2.3 Million\n",
       "20                     Pagani Utopia          Price: $2.4 Million\n",
       "21              Pininfarina Battista          Price: $2.5 Million\n",
       "22                 Ferrari FXX K Evo          Price: $2.5 Million\n",
       "23                Gordon Murray T.50          Price: $2.6 Million\n",
       "24              Lamborghini Countach          Price: $2.6 Million\n",
       "25          Mercedes-AMG Project One          Price: $2.6 Million\n",
       "26               Aston Martin Victor          Price: $2.7 Million\n",
       "27       Hennessey Venom F5 Roadster          Price: $3.0 Million\n",
       "28                  Koenigsegg Jesko                 $3.0 Million\n",
       "29             Aston Martin Valkyrie          Price: $3.0 Million\n",
       "30         W Motors Lykan Hypersport          Price: $3.2 Million\n",
       "31                     McLaren Solus          Price: $3.4 Million\n",
       "32         Pagani Huayra Roadster BC                 $3.5 Million\n",
       "33          Bugatti Chiron Pur Sport          Price: $3.5 Million\n",
       "34                  Lamborghini Sian          Price: $3.6 Million\n",
       "35                  Koenigsegg CC850          Price: $3.6 million\n",
       "36   Bugatti Chiron Super Sport 300+          Price: $3.7 Million\n",
       "37                Lamborghini Veneno          Price: $3.9 Million\n",
       "38                    Bugatti Bolide          Price: $4.5 Million\n",
       "39                   Bugatti Mistral          Price: $4.7 Million\n",
       "40               Pagani Huayra Imola          Price: $5.0 Million\n",
       "41                      Bugatti Divo          Price: $5.4 Million\n",
       "42               SP Automotive Chaos          Price: $5.8 Million\n",
       "43                  Pagani Codalunga          Price: $6.4 Million\n",
       "44          Mercedes-Maybach Exelero          Price: $7.4 Million\n",
       "45                Bugatti Centodieci          Price: $8.0 Million\n",
       "46           Bugatti Chiron Profilée          Price: $9.0 Million\n",
       "47              Rolls-Royce Sweptail         Price: $10.8 Million\n",
       "48          Bugatti La Voiture Noire         Price: $12.8 Million\n",
       "49            Rolls-Royce Boat Tail*         Price: $13.4 Million\n",
       "50  Most Expensive Cars In The World  Price: $28.0 Million (est.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty lists to store the scraped data\n",
    "cars_name = []\n",
    "cars_price = []\n",
    "\n",
    "# Find all the car tags using XPath and append the text of each tag to the `cars_name` list\n",
    "cars_tags = driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in cars_tags:\n",
    "    cars_name.append(i.text)\n",
    "\n",
    "# Find all the price tags using the `TAG_NAME` locator for `strong` tags and append the text of each tag to the `cars_price` list\n",
    "price_tags = driver.find_elements(By.TAG_NAME,'strong')\n",
    "for i in price_tags:\n",
    "    cars_price.append(i.text)\n",
    "\n",
    "# Create a pandas dataframe from the scraped data and display it\n",
    "df_cars = pd.DataFrame({'Car Name':cars_name,'Price':cars_price})\n",
    "\n",
    "# dropping the rows having NaN values\n",
    "df = df_cars.drop(3)\n",
    " \n",
    "# To reset the indices\n",
    "df = df.reset_index(drop=True)\n",
    " #Set the DataFrame index to start from 1 instead of the default 0\n",
    "df.index = range(1, len(df)+1)\n",
    "# Print the dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cbb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
